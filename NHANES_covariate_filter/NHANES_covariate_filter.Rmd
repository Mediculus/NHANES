---
title: "Directed EDA for rnhanes Package"
author: "Kevin S.W. --- UNI: ksw2137"
date: "`r format(Sys.time(), '%x')`"
output: github_document
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}

# global default settings for chunks
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, message = FALSE,
                      fig.dim = c(10, 4), 
                      fig.align = "center")

# loaded packages; placed here to be able to load global settings
Packages <- c("tidyverse", "dplyr", "httr", "rvest")
invisible(lapply(Packages, library, character.only = TRUE))



# global settings for color palettes
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

# theme global setting for ggplot
theme_set(theme_minimal() + 
            theme(legend.position = "bottom") +
            theme(plot.title = element_text(hjust = 0.5, size = 12),
                  plot.subtitle = element_text(hjust = 0.5, size = 8))
          )

```

# Filtering Covariate Data of Interest

Since we've explored almost all possible datasets that can be found in the `rnhanesdata` package, we can now make a more targeted approach to which dataset we want to work on as well as obtaining particular raw data information. First though, we need to load the package as always.

```{r package_load}

library(rnhanesdata)

```

## Picking which NHANES Data

The original package has 2 waves, C and D, that corresponds to surveys sent out between 2003-2004 and 2005-2006, respectively. Working with wave D has advantage because not only is the data more recent, it also has more "raw" observations and thus potentially more datapoints we could work with. 

```{r raw_covar_load, results = "hide"}

covar_data_d <- as_tibble(
  process_covar(
    waves = "D", extractAll = TRUE
    )[[1]] # process_covar outputs a list of 1 containing the tibble, this extracts the "content" and 
  ) %>%    # turn it into tibble
  janitor::clean_names()

covar_names <- names(covar_data_d)

```

We can then filter out these observations to only include those that may be useful for accelerometer and flag data (in case we ever want to explore relationships between these variables).

First, we load up the flag data, `Flags_D` to obtain the unique ID of each participants (`seqn`). The reason why we used flag data is because we only wanted participants who have information on their wearable status (whether it is "reliable" or not at a given minute/time).

```{r seqn_obtain}

identifier <- Flags_D %>% 
  janitor::clean_names() %>% 
  distinct(seqn) %>% 
  mutate(
    seqn = as.integer(seqn)
  )

covar_data_d <- left_join(identifier, covar_data_d, by = 'seqn')

```

## Filtering our Covariates Data

In another document, we've succesfully created a .csv file that contained all the variables of interest with respect to variables that might be associated with cardiovascular health. We can use that .csv file to filter our `covar_data_d`, which will then allow us to proceed in analyzing the data. 

```{r covar_filtering}

variable_list <- read_csv("./Datasets/variable_list.csv")

covar_d_clean <- select_if(covar_data_d, 
                           names(covar_data_d) %in% pull(variable_list, var_name))

```

## Exploring Data Frame

We would like to explore our clean data now and firstly check the amount of `NA` in each column. 

```{r NA_check}

na_check_df <- covar_d_clean %>% 
  map_df(~sum(is.na(.))) %>% 
  pivot_longer(2:103,
               names_to = "var_name",
               values_to = "na_count") %>% 
  arrange(desc(na_count)) 

```

Upon arranging the resulting `NA` count into a descending order, something peculiar showed, which is that the variables `padtimes`, `padactiv`, and `padlevel` from the package appear to have more `NA` compared to the number of `seqn` (respondents). Investigating it further leads to the finding that this particular variable is saved as a vector variable, containing many more observations. Thankfully, this is likely to be redundant variable when we consider including our activity level data from the package. Thus decision was made to exclude these.

```{r remove_pad_vars}

na_check_df <- na_check_df %>% 
  filter(!(var_name %in% c("padtimes", "padactiv", "padlevel")))

```


```{r filter_NA, echo = FALSE, eval = FALSE}

#We then evaluate from the remaining `r nrow(na_check_df)` variables and felt that an `NA` amount that is >`r round(100*((7455-1000)/7455), 3)`% would not be a good representative of the variable. Therefore, we filtered all those that have values greater than `r 7455*(7455-1000)/7455`. 

#na_check_df <- na_check_df %>% 
#  filter( na_count < 6455)

```

## Re-selecting Viable Variables for Data Analysis 

Now that we've set a level of acceptable responses, we could revisit our variables and be more selective.

```{r}

clean_variable_list <- left_join(na_check_df, variable_list, by = "var_name")

```

Revising the variables, these are the ones we decide to NOT include:

* mcq010: asthma dx
* mcq025: age of 1st asthma
* mcq035: still have asthma currently
* mcq300a: close relative had MI?
* mcq300b: close relative had asthma?
* mcq300c: close relative had diabetes?
* bmxsub: subscapular skinfold (mm)
* dmdeduc3: education level - children 6-19
* dmdfmsiz: total # of people in the family
* sdmvpsu: masked variance pseudo-psu
* sdmvstra: masked variance pseuda-stratum

```{r 2nd_var_remove}

filter_remove_list <- 
  c("mcq010", "mcq025", "mcq035", "mcq300a", "mcq300b", "mcq300c", "bmxsub", "dmdfmsiz", "sdmvpsu", "sdmvstra")

clean_variable_list <- clean_variable_list %>% 
  filter(!(str_detect(var_name, 
                      paste(filter_remove_list,            
                            collapse = "|"))))

```

We then further re-clean our `covar_d_clean` dataframe

```{r recleaned_covar}

covar_d_clean <- select_if(covar_data_d, 
                           names(covar_data_d) %in% c("seqn", pull(clean_variable_list, var_name)))

```

We now check for any distributions, min-max and so on using `skimr`

```{r skim_data}

skimr::skim(covar_d_clean)

```

Once we check distributions and satisfied with results, we should also make this into another dataset so that we don't have to keep re-running the scripts.

```{r}

# covar_d_clean %>% write_csv("./Datasets/covariates.csv")

```



# Combining Covariates and Activity Data

**MOVE THIS PART TO A NEW RMD**

Now that we have covariates we can work with, it's time to merge these with our activity data. But first, we need to clean our activity records using the flags dataset. 

```{r activity_wave_datamerge, echo = FALSE, eval = FALSE}

activity_data_d <- PAXINTEN_D %>% 
  janitor::clean_names() %>% 
  pivot_longer(cols = starts_with("MIN"), 
               names_to = "min",
               names_prefix = "min",
               values_to = "activ_count") %>% 
  mutate(
    min = as.numeric(min)
  ) %>% 
  mutate_at(                                             # convert listed variables to factors
    .vars = vars("paxcal", "paxstat", "weekday", "sddsrvyr"),
    .funs = funs(factor)
  )



flag_d <- unnest(flag_d) %>% 
  unnest() %>% 
  pivot_longer(cols = starts_with("MIN"), 
               names_to = "min",
               names_prefix = "min",
               values_to = "flag_indicator") %>% 
  mutate(
    min = as.numeric(min)
  )


activity_flag_joined <- 
  left_join(
    activity_data_d, 
    flag_d, 
    by = c("seqn", "paxcal", "paxstat", "weekday", "sddsrvyr", "min")) 

activity_flag_joined <- activity_flag_joined %>%
  filter(flag_indicator != 0)
  
```


