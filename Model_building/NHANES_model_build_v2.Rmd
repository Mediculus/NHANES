---
title: "Predictive Model Building v2"
author: "Kevin S.W. --- UNI: ksw2137"
date: "`r format(Sys.time(), '%x')`"
output: github_document
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}

# global default settings for chunks
knitr::opts_chunk$set(echo = TRUE, 
                      fig.dim = c(10, 4), 
                      fig.align = "center",
                      results = "asis"
                      )

# loaded packages; placed here to be able to load global settings
Packages <- c("tidyverse", "dplyr")
invisible(lapply(Packages, library, character.only = TRUE))



# global settings for color palettes
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

# theme global setting for ggplot
theme_set(theme_minimal() + 
            theme(legend.position = "bottom") +
            theme(plot.title = element_text(hjust = 0.5, size = 12),
                  plot.subtitle = element_text(hjust = 0.5, size = 8))
          )

```

# Predictive Model Building

Packages needed will be `parsnip`, `caret`, and `yardstick`. 

## Package load

There are several packages that we will use in order to start our model building and these will be specified prior to a specific model building. For this particular portion, we will do LASSO regression and will need the `glmnet` package. 

```{r}

library(caret)
library(yardstick)

```


## LASSO Model Building

### Data loading

Recall all the busy data-cleaning that we did prior, we can now finally use it to build some predictive modeling.

```{r}

nhanes_df <- read_csv("./Datasets/cleaned_dataset_v2.csv") %>% 
  mutate(age_group = case_when(age_yrs <= 18 ~ "non-adult",
                               age_yrs > 18 ~ "adult")) %>% 
  mutate(across(where(is.character), factor))
  

skimr::skim_without_charts(nhanes_df)

```

We see above that we have loaded it in and converted our factor variables back as factors.

We also added an indicator variable for those aged $\leq 18$ yrs (teenagers) and $> 18$ yrs (adults) for potential stratification purposes though we probably won't use it in our predictive model at the moment. 

### Dataset Preparation

As said earlier, our `age_group` variable is likely not part of our current model so we will remove that column.

```{r}

lasso_data <- nhanes_df %>% 
  select(-pid, -age_group, -insulin)

```

### Using caret

Load `caret` and start building:

```{r}

set.seed(1)

#LASSO controls & grid
lasso_control <- trainControl(method = "repeatedcv",
                        number = 5, repeats = 5,
                        search = "random")

#lasso_grid <- expand.grid(alpha = 1, lambda = 10^(seq(5, -5, -0.1)))




# bootstrapped data partitioning to train and test
train_index <- createDataPartition(lasso_data$diabetes, p = 0.8, list = FALSE, times = 1)

train_df <- lasso_data[train_index,]
test_df <- lasso_data[-train_index,]


# dummy vars
dv_data <- dummyVars(diabetes ~ ., train_df)

dv_df <- predict(dv_data, newdata = train_df)

# preprocess
pP <- preProcess(dv_df, method = c('knnImpute', 'center', 'scale'))

pp_dv_df <- predict(pP, newdata = dv_df)



# model fit
lasso_fit <- train(x = pp_dv_df, y = train_df$diabetes, 
                   data = train_df,
                   method = "glmnet",
                   trControl = lasso_control, 
                   family = "binomial")


lasso_pred <- predict(lasso_fit, test_df)
# compare predicted outcome and true outcome
confusionMatrix(lasso_pred, test_df$diabetes)


varImp(lasso_fit)

lasso_fit

coef(lasso_fit$finalModel, lasso_fit$bestTune$lambda)

```

# Random Forest


```{r}

rf_control <- trainControl(method = "repeatedcv",
                        number = 5, repeats = 5,
                        search = "grid")

rf_grid <- expand.grid(mtry = 1:5)

rf_fit <- train(diabetes ~., data = train_df,
                   method = "rf",
                   trControl = rf_control, 
                   tuneGrid = rf_grid,
                ntree = 200)

varImp(rf_fit)

print(rf_fit)


rf_pred <- predict(rf_fit, test_df)
# compare predicted outcome and true outcome
confusionMatrix(rf_pred, test_df$diabetes)

```

# Evaluating Models

We will use `yardstick` package to evaluate which of the two models are better. 

```{r}

library(yardstick)

```

```{r}

yardstick_test <- two_class_example

metrics(yardstick_test, truth, predicted)

```


# Potentially helpful tools for random forest/lasso

Consider parsnip, caret, yardstick (possible tools to compare models)
