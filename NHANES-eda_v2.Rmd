---
title: "Directed EDA for rnhanes Package"
author: "Kevin S.W. --- UNI: ksw2137"
date: "`r format(Sys.time(), '%x')`"
output: github_document
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}

# global default settings for chunks
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE, message = FALSE,
                      fig.dim = c(10, 4), 
                      fig.align = "center",
                      results = "asis"
                      )

# loaded packages; placed here to be able to load global settings
Packages <- c("tidyverse", "dplyr", "httr", "rvest")
invisible(lapply(Packages, library, character.only = TRUE))



# global settings for color palettes
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

# theme global setting for ggplot
theme_set(theme_minimal() + 
            theme(legend.position = "bottom") +
            theme(plot.title = element_text(hjust = 0.5, size = 12),
                  plot.subtitle = element_text(hjust = 0.5, size = 8))
          )

```

# Re-fresh start for NHANES dataset

Since we've explored almost all possible datasets that can be found in the `rnhanesdata` package, we can now make a more targeted approach to which dataset we want to work on as well as obtaining particular raw data information. First though, we need to load the package as always.

```{r package_load}

library(rnhanesdata)

```

## Picking which NHANES Data

The original package has 2 waves, C and D, that corresponds to surveys sent out between 2003-2004 and 2005-2006, respectively. Working with wave D has advantage because not only is the data more recent, it also has more "raw" observations and thus potentially more datapoints we could work with. 

```{r raw_covar_load}

covar_data_d <- as_tibble(
  process_covar(
    waves = "D", extractAll = TRUE
    )[[1]] # process_covar outputs a list of 1 containing the tibble, this extracts the "content" and 
  ) %>%    # turn it into tibble
  janitor::clean_names()

```

We can then filter out these observations to only include those that may be useful for accelerometer and flag data (in case we ever want to explore relationships between these variables).

First, we load up the flag data:

```{r flag_data_prep}

flag_d <- Flags_D %>% 
  janitor::clean_names() %>% 
#  pivot_longer(cols = starts_with("MIN"),               # code-line for cases where we want to switch to
#               names_to = "min",                        # long format
#               names_prefix = "min",
#               values_to = "flag_indicator") %>% 
#  mutate(
#    min = as.numeric(min)
#  ) %>% 
  mutate_at(                                             # convert listed variables to factors
    .vars = vars("paxcal", "paxstat", "weekday", "sddsrvyr"),
    .funs = funs(factor)
  ) %>% 
  group_by(seqn) %>%                                     # grouping by the unique ID
  nest(flag_mins = min1:min1440) %>%                     # nesting of the "minutes" for flag
  nest(wave_D = paxcal:flag_mins)                        # nested the "extra variables". 

```

The purpose of the code above is to prepare a condensed dataset that ready-to-use whenever we need to start investigation on variables of interest. For now though, we will only use `seqn` as an identifier for merging other datasets. Below, we will use `seqn` to essentially filter out all the covariate data to only include those that are in the `flag_d` dataset. 

```{r covar_data_merge}

identifier <- flag_d %>% 
  select(seqn) %>% 
  ungroup() %>% 
  mutate(
    seqn = as.integer(seqn)
  )

covar_data_d <- left_join(identifier, covar_data_d, by = 'seqn')

```

Now that we have filtered out our raw covariates data, we can further stratify our datasets into lists for specific questionnaires and tackle this 1-by-1.

```{r}

nested_covar_data_d <- covar_data_d %>% 
  group_by(seqn) %>% 
  nest(alc_q = alq101:alq150)

nested_covar_data_d

```

Next step however, is to select relevant variables...

# Code Book of Covariates from CDC

## Figuring out Relevant Variables to use in Raw Covar Data

### Obtaining Variable Descriptions

By consulting CDC's [NHANES website](https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Demographics&CycleBeginYear=2005), we could check 1-by-1 which variables are actually relevant to our interest. As tedious as it was, unfortunately this is the only method that can be done without further assistance. 

First, we need a function to grab these descriptions. 

```{r info_grab_fn}

# page-reader function
read_page <- function(url, tag) {
  
  h = read_html(url)               # reads url input
  
  data_name = h %>%
    html_nodes(tag) %>%            # pulls the specific html tag (for titles)
    html_text()
  
  data_frame(data_name)            # turns scraped data into a dataframe
}

```

Now that we have a page-reader function, we can first scrape all the available "survey" documents' names.  
Notes on removed variables:

* `All Years`, `VID_D`: different link
* `DSBI`, `DSII`, `DSPI`, `RXQ_DRUG`: data from 1999-2000? (likely aggregate data and too difficult to process)

```{r NHANES_data_process}

# obtaining survey type/and its topic-contents
survey_filedata <- 
  tibble(
    survey_link = c(
      "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Demographics&CycleBeginYear=2005",  # demographics
      "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Dietary&CycleBeginYear=2005",       # dietary  
      "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Examination&CycleBeginYear=2005",   # examination
      "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Laboratory&CycleBeginYear=2005",    # laboratory
      "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Questionnaire&CycleBeginYear=2005", # questionnaire
      "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Non-Public&CycleBeginYear=2005"     # limited data
      ),
    # categorizing based on CDC's classification of survey
    survey_type = c("demographics", "dietary", "examination", "laboratory", "questionnaire", "limited_data")
  ) %>% 
  # two different major link; add "indicator". as well as obtain "group variable/topic" description and its "filename".
  mutate(
    survey_type = factor(survey_type),
    limited_data = case_when(survey_link != "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Non-Public&CycleBeginYear=2005" ~ FALSE,
                             survey_link == "https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Non-Public&CycleBeginYear=2005" ~ TRUE),
    data_desc = map2(.x = survey_link, .y = "td.text-left", ~read_page(url = .x, tag = .y)),
    filedata = map2(.x = survey_link, .y = ".text-center:nth-child(2) a", ~read_page(url = .x, tag = .y))
    ) %>% 
  unnest() %>%   
  rename(
    data_desc = data_name,                # description of the file-name
    filedata = data_name1                 # file name for the particular "data category". 
  ) %>% 
  select(-survey_link) %>%                # remove now-useless column
  mutate(
    filedata = gsub(" Doc", "", filedata) # remove the "Doc" text at the end of every filename in filedata
    ) %>% 
  filter(!(filedata %in% c("All Years", "VID_D", "DSBI", "DSII", "DSPI", "RXQ_DRUG"))) # remove the odd-one-out survey links





# obtain the contents of each survey topic and removing now-unused variables 
filtered_survey_filedata <- survey_filedata %>%
  mutate(
    var_url = case_when(limited_data == FALSE ~ str_c("https://wwwn.cdc.gov/Nchs/Nhanes/2005-2006/", filedata, ".htm"),
                        limited_data == TRUE ~ str_c("https://wwwn.cdc.gov/Nchs/Nhanes/limited_access/", filedata, ".htm")
    )
  ) %>% 
  mutate(
    var_content = map2(.x = var_url, .y = "#CodebookLinks a", ~read_page(url = .x, tag = .y))
  ) %>% 
  select(-var_url, -limited_data)

# just to check if there's any duplicate filedata variables
#distinct(filtered_survey_filedata, filedata, .keep_all = TRUE)

```

Now that we have the "list of descriptions", we could scan which variables/topics are of interest to us. We are particularly interested in variables potentially related to cardiovascular function. 

Note however that `nrow =` `r nrow(filtered_survey_filedata` has 3 more variables when compared to `distinct(filtered_survey_filedata, filedata) =` `r nrow(distinct(filtered_survey_filedata, filedata))`, suggesting that there are some duplicates (see below).

```{r surveydf_dupe_check}

janitor::get_dupes(filtered_survey_filedata, filedata)

```

As we can see, the duplicates are likely from slightly different descriptions of the HPV tests. Thankfully we aren't interested in these variables so we can "remove the duplicates" later. 

### Obtaining Detailed Version of Descriptions

Another step we need to do is the add clarifying descriptions as some of these variables are still unclear.

```{r detailed_var_desc_scrape}

detailed_var_desc <- survey_filedata %>% 
  select(survey_type, limited_data) %>% 
  distinct(survey_type, .keep_all = TRUE) %>%       # obtaining the survey type variables
  # adding url for each survey type
  mutate(
    detailed_var_url = 
      case_when(limited_data == FALSE ~ 
                  str_c("https://wwwn.cdc.gov/nchs/nhanes/Search/variablelist.aspx?Component=", 
                        survey_type, "&CycleBeginYear=2005"),
                limited_data == TRUE ~
                  "https://wwwn.cdc.gov/nchs/nhanes/Search/variablelist.aspx?CycleBeginYear=2005&Component=Non-Public")
    ) %>% 
  # obtaining variable ID and the detailed descriptions
  mutate(
    var_name = map2(.x = detailed_var_url, .y = "td:nth-child(1)", ~read_page(url = .x, tag = .y)),
    detailed_var_content = map2(.x = detailed_var_url, .y = "td:nth-child(2)", ~read_page(url = .x, tag = .y)),
    filedata = map2(.x = detailed_var_url, .y = "td:nth-child(3)", ~read_page(url = .x, tag = .y))
  ) %>% 
  select(-limited_data, -detailed_var_url) %>% 
  unnest() %>% 
  rename("var_name" = data_name,
         "det_var_desc" = data_name1,
         "filedata" = data_name2)

```

### Removing Irrelevant Variables

Unfortunately, this is one of the more time-consuming portion and tedious as we need to evaluate each variable by eye to determine which variables are of specific interest. Thankfully, our `data_desc` variable can help us remove variables that are definitely NOT interesting.

Removed data based on `data_desc` that are unlikely to be related to cardiovascular issues:

* Demographic:
  * None
  
* Dietary:
  * None
  
* Exam Survey:
  * Audiometry -containing descriptions
  * Dual Energy X-ray -containing descriptions
  * Ophthalmology -containing descriptions
  * Oral Health
  * Vision

* Lab Survey:
  * Acrylamide & Glycidamide
  * Allergen -containing descriptions
  * Arsenics
  * Brominated Flame Retardants
  * Cadmium, Lead, & Total Mercury - Blood
  * Chlamydia & Gonorrhea - Urine
  * Cotinine - Serum
  * Environmental Phenols & Parabens
  * Epstein-Barr Virus
  * Erythrocyte Protoporphyrin
  * Fasting Questionnaire
  * Ferritin
  * Folate
  * HepA Ab
  * HepB Surface Ab
  * HepB Core Ab
  * HepC Confirmed Ab
  * HSV Type-1 & Type-2
  * HIV Ab Test, CD4+ T Lymphocytes & CD8+ T Cells
  * HPV -containing descriptions
  * Iodine - Urine
  * Iron, TIBC
  * Mercury -containing descriptions
  * Metals - Urine
  * Non-dioxin-like Polychlorinated...
  * Organophosphate Insecticides...
  * PTH
  * Perchlorate -containing descriptions
  * Pesticides -containing descriptions
  * Phthalates - Urine
  * Phytoestrogens
  * Polychlorinated dibenzo-p-dioxins
  * Polyfluoroalkyl Chemicals
  * Pooled-Sample Technical Support File
  * Pregnancy Test - Urine
  * PSA
  * Salmonella & Campylobacter Ab (Surplus)
  * Transferrin Receptor
  * Volatile Organic Compounds -containing descriptions.
  
* Questionnaire:
  * Acculturation
  * Allergy
  * Audiometry
  * Dermatology
  * HepC Follow Up
  * Kidney Conditions - Urology
  * Mental Health - Depression Screener
  * Oral Health
  * Osteoporosis
  * Pesticide Use
  * Prostate Conditions
  * PSA Follow-up
  * Reproductive Health
  * Sexual Behavior
  * Sleep Disorders
  * Vision

* Limited Data:
  * Chlamydie & Gonorrhea - Urine
  * HSV Type-2 Youth
  * HPV -containing descriptions
  * Los Angeles County, California - Demographic Variables
  * Mental Health - Depression Screener
  * Sexual Behavior - Youth

These are the first step in filtering our incredibly large dataset. The next step is then to further filter out the items contained within the remaining `filedata`.

```{r remove_filedata}

# list of group variable to be removed
remove_list <- c("Audio", "X-ray", "Ophthalmol", "Oral", "Vision", "Acrylamide", "Allerg", 
                 "Arsenics", "Brominated", "Cadmium", "Chlamydia", "Cotinine", "Environmental", "Epstein-Barr", 
                 "Erythrocyte Protoporphyrin", "Fasting Questionnaire", "Ferritin", "Folate", "Hepatitis",
                 "Herpes Simplex Virus", "HIV", "Human Papillomavirus", "Iodine", "Iron", "Mercury", "Metals", "Non-dioxin-like",
                 "Organophosphate", "Parathyroid", "Perchlorate", "Pesticide", "Phthalates", "Phytoestrogens", "Polychlorinated",
                 "Polyfluoroalkyl", "Pooled-Sample", "Pregnancy Test", "Prostate", "Salmonella", "Transferrin",
                 "Volatile Organic Compounds", "Acculturation", "Dermatology", "Kidney Conditions", "Mental Health", 
                 "Oral Health", "Osteoporosis", "Reproductive Health", "Sleep Disorders", "Los Angeles County", "Sexual")


# curated filedata that removes all those in the remove_list
selected_filedata <- filtered_survey_filedata %>% 
  filter(!(str_detect(data_desc, 
                      paste(remove_list,               # remove using a combination of !, str_detect, paste funcs
                            collapse = "|")))) %>%     # collapse "merges" the list with the specified char as the "space"
  unnest() %>%                                         # reveal variables (to cross ref with rnhanesdata)
  separate(data_name,                                  # separate the variable into the "variable name" and its decription
           into = c("var_name", "var_desc"),
           sep = " - ",
           extra = "merge")                            # used to separate only by the "first seen" separator.

```

Now that we have filtered out unwanted group variables, we can check for duplicate variables using `janitor::get_dupes` function. 

```{r selecteddf_dupe_check}

janitor::get_dupes(selected_filedata, var_name) %>% 
  view()

```

Unfortunately, as seen by the function, there were multiple duplicate variables that are subset by different group-variables and thus we cannot efficiently remove this with `distinct()`. To make this more manageable, we should subset this by each survey category. 

Given our smaller dataset now, we can merge the detailed description to our description dataset. 

```{r left_join_detailed}

det_selected_df <- left_join(selected_filedata, 
                               detailed_var_desc,
                               by = c("survey_type", "filedata", "var_name"))

```

After obtaining a more comprehensive description dataset, we always check for duplicates, especially considering that our `det_selected_df` (merged df) contains `r nrow(det_selected_df)` rows while our `selected_filedata` only has `r nrow(selected_filedata)` rows. 

```{r detailedselecteddf_dupe_check}

janitor::get_dupes(det_selected_df, filedata, var_name)

```

As we see above, there were 52 rows of duplicates. If we were to divide it by 2, we get 26. This corresponds nicely to the difference between our `det_selected_df` and `selected_filedata`. Also suggests that there's only 2 copies of each `var_name`. Having cross-checked with CDC's descriptions that doesn't appear to show any particular difference, we could safely use `distinct()` to filter these out. However, to ensure there's no "missing information", we decided to remove duplicates with exact matches in three columns, `filedata`, `var_name`, and `det_var_desc`. 

```{r detailedselecteddf_remove_dupe}

det_selected_df <- distinct(det_selected_df, 
                             filedata, var_name, det_var_desc, 
                             .keep_all = TRUE)

```

### Demographic Data

```{r demo_survey}

demo_survey <- det_selected_df %>% 
  filter(survey_type == "demographics") %>% 
  select(-survey_type, -data_desc, -filedata)

```

Under demographic survey data, we see that variables of interest are:

* SEQN: Sequence number
* SDDSRVYR: Data release number (likely "wave" ID)
* RIDSTATR: Interview (1) or interview + exam (2), NA otherwise
* RIAGENDR: Gender
* RIDAGEYR: Age at screening in years
* RIDRETH1: Ethnicity
* DMDEDUC3: Education level (aged 6-19)
* DMDEDUC2: Education level (aged 20+)
* DMDFMSIZ: Number of people in Family
* INDFMINC: Annual family income
* INDFMPIR: Family Poverty Income Ratio (PIR; family income:poverty threshold)
* WTINT2YR: Full sample 2-year interview weight
* WTMEC2YR: Full sample 2-year MEC exam weight
* SDMVPSU: Masked variance pseudo-PSU
* SDMVSTRA: Masked variance pseudo-stratum

From these, we could build a "keep-list" for our demographic data.

```{r demo_var_keep}

demo_keep_list <- c("SEQN", "SDDSRVYR", "RIDSTATR", "RIAGENDR", "RIDAGEYR", "RIDRETH1", "DMDEDUC3", "DMDEDUC2",
                    "DMDFMSIZ", "INDFMINC", "INDFMPIR", "WTINT2YR", "WTMEC2YR", "SDMVPSU", "SDMVSTRA")

demo_survey <- demo_survey %>% 
  filter((str_detect(var_name, 
                      paste(demo_keep_list,            
                            collapse = "|"))))

```

### Dietary Data

We can do similar steps with our dietary data.

```{r diet_survey}

diet_survey <- det_selected_df %>% 
  filter(survey_type == "dietary") %>% 
  select(-survey_type, -filedata)

# used to check "unique" data descriptions to quickly filter out which categories might be of interest to explore
#distinct(diet_survey, var_name)

```

Of interest:

* SEQN
* DR1ILINE: Another key variable for dietary data; "food/individual" component number
* Dietary Interview - Total Nutrient Intakes, First Day:
  * DBD100: How often adding salt to food
  * DRQSDIET: On special kinds of diet to lose weight/other health-related reason (followed by options if yes)
    * DRQSDT1: weight loss (lowcal/carb/hiprot diet)
    * DRQSDT2: lowfat/lowcholes diet
    * DRQSDT3: Low salt diet
    * DRQSDT4: Sugar-free/low sugar diet
    * DRQSDT5: Low-fiber diet
    * DRQSDT6: high-fiber diet
    * DRQSDT7: diabetic diet
    * DRQSDT8: weight-gain/muscle building diet
    * DRQSDT91: other special diet
  * DR1TKCAL: energy (kcal)
  * DR1TPROT: protein (gm)
  * DR1TCARB: carbs (gm)
  * DR1TSUGR: total sugars (gm)
  * DR1TFIBE: dietary fibers (gm)
  * DR1TTFAT: total fat (gm)
  * DR1TSFAT: total sat. FA (gm)
  * DR1TMFAT: total monounsat. FA (gm)
  * DR1TPFAT: total polyunsat. FA (gm)
  * DR1TCHOL: cholesterol (mg)
  * DR1_320Z: total plain water drank yesterday (gm)
  * DR1_330Z: total tap water drank yesterday (gm)
  * DR1BWATZ: total bottled water drank yesterday (gm)
* Dietary Interview - Total Nutrient Intakes, Second Day:
  * DR2TKCAL: energy (kcal)
  * DR2TPROT: protein (gm)
  * DR2TCARB: carbs (gm)
  * DR2TSUGR: total sugars (gm)
  * DR2TFIBE: dietary fibers (gm)
  * DR2TTFAT: total fat (gm)
  * DR2TSFAT: total sat. FA (gm)
  * DR2TMFAT: total monounsat. FA (gm)
  * DR2TPFAT: total polyunsat. FA (gm)
  * DR2TCHOL: cholesterol (mg)
  * DR2_320Z: total plain water drank yesterday (gm)
  * DR2_330Z: total tap water drank yesterday (gm)
  * DR2BWATZ: total bottled water drank yesterday (gm)

```{r diet_var_keep}

diet_keep_list <- c("SEQN", "DR1ILINE", "DBD100", "DRQSDIET", "DRQSDT1", "DRQSDT2", "DRQSDT3", "DRQSDT4", "DRQSDT5", "DRQSDT6", "DRQSDT7", "DRQSDT8", "DRQSDT91", "TKCAL", "TPROT", "CARB", "TSUGR", "TFIBE", "TTFAT", "TSFAT", "TMFAT", "TPFAT", "TCHOL", "320Z", "330Z", "BWATZ")

diet_survey <- diet_survey %>% 
  filter(!(str_detect(data_desc, "Individual|Questionnaire|Supplement")), 
         (str_detect(var_name, 
                      paste(diet_keep_list,            
                            collapse = "|"))))

```

### Examination Data

```{r exam_survey}

exam_survey <- det_selected_df %>% 
  filter(survey_type == "examination") %>% 
  select(-survey_type, -filedata)

# used to check "unique" data descriptions to quickly filter out which categories might be of interest to explore
#janitor::get_dupes(exam_survey, var_name)

#exam_survey %>% 
#  distinct(var_name)

```

Variables of Interest: 

* Blood Pressure:
  * SEQN
  * PEASCST1: BP status
  * BPXCHR: 60sec HR (30s x 2)
  * BPXPLS: 60sec pulse (30s x2); duplicate of BPXCHR?
  * BPXPULS: pulse reg/irreg
  * BPXPTY: pulse type
  * BPXSY*: systolic BP readings:
    * 1: 1st reading
    * 2: 2nd reading
    * 3: 3rd reading
    * 4: 4th reading
  * BPXDI*: diastolic BP readings:
    * 1: 1st reading
    * 2: 2nd reading
    * 3: 3rd reading
    * 4: 4th reading
* Body Measures:
  * SEQN
  * BMXWT: weight (kg)
  * BMXHT: standing height (cm)
  * BMXBMI: BMI (kg/m^2)
  * BMXCALF: max calf circumference (cm)
  * BMXARMC: arm circumference (cm)
  * BMXWAIST: waist circumference (cm)
  * BMXTHICR: thigh circumference (cm)
  * BMXTRI: triceps skinfold (mm)
  * BMXSUB: subscapular skinfold (mm)
* Physical Activity Monitor
  * None from raw (provided in `rnhanesdata` package)

```{r exam_var_keep}

exam_keep_list <- c("SEQN", "PEASCST1", "BPXCHR", "BPXPLS", "BPXPULS", "BPXPTY", "BPXSY", "BPXDI", "BMXWT", "BMXHT", "BMXBMI", "BMXCALF", "BMXARMC", "BMXWAIST", "BMXTHICR", "BMXTRI", "BMXSUB")

exam_survey <- exam_survey %>% 
  filter(str_detect(var_name, 
                      paste(exam_keep_list,            
                            collapse = "|")))

```

### Laboratory Data

```{r lab_survey}

lab_survey <- det_selected_df %>% 
  filter(survey_type == "laboratory") %>% 
  select(-survey_type, -filedata)

# used to check "unique" data descriptions to quickly filter out which categories might be of interest to explore
#janitor::get_dupes(lab_survey, var_name)

```

Thankfully, the lab survey has initially been filtered by the kind of tests that were undertaken by each subjects. As such, all components from those `data_desc` under `laboratory` will be of interest. To recap, the lab tests that were kept are:

* Urine Albumin/Creatinine
* Lipid panel
* CBC w/ diff
* CRP
* HbA1C (glycohemoglobin)
* Hemocysteine
* Plasma fasting glucose & insulin
* Urine Polyaromatic Hydrocarbons (PAH)
* CMP (standard biochem profile)
* Vit A, E & carotenoids
* Vit B12
* Vit B6
* Vit C

### Questionnaire Data

```{r que_survey}

que_survey <- det_selected_df %>% 
  filter(survey_type == "questionnaire") %>% 
  select(-survey_type, -filedata)

# used to check "unique" data descriptions to quickly filter out which categories might be of interest to explore
janitor::get_dupes(que_survey, var_name)

```

Questionnaires of interest:

* Alcohol Use:
  * ALQ120Q: how often drinking etOH past 12 months.
  * ALQ120U: unit of measure (# days of drinking etOH /wk, month, or yr)
* Blood Pressure & Cholesterol
  * BPQ040A: taking rx for HTN
  * BPQ070: when blood cholesterol last checked
  * BPQ080: told by md, HLD
  * BPQ090*: recommendations for dealing with HLD
    * A: told to eat less fat
    * B: told to reduce weight
    * C: told to exercise more
    * D: told to take rx
* Cardiovascular Health
  * All
* Current Health Status
  * HSD010: general health condition
* Diabetes
  * All
* Diet Behavior & Nutrition
  * None
* Drug use
  * None
* Early Childhood
  * None
* Food Security
  * FSD032:
    * A: worried about running out of food
    * B: food didn't last
    * C: couldn't afford balanced meal
    * D: 
    * E:
    * F:
  * FSD041: adults cut size/skip meals
  * FSD052: How often adults cut size/skip meals
  * FSD061: eating less than they should in the past 12 months
  * FSD071: hungry but didn't eat in the past 12 months
  * FSD081: lost weight because no money for food in the past 12 months
  * FSD092: any adults in the household not eat for whole day b/c no money
  * FSD102: how often do these adults not eat for a whole day?
* Health Insurance
  * None
* Hospital Utilization & Access to Care
  * None
* Housing Characteristics
  * None
* Immunization
  * None
* Medical Conditions
  * MCQ010: Asthma Dx
  * MCQ025: Age 1st asthma
  * MCQ035: Still with asthma
  * MCQ080: Overweight told by MD.
  * MCQ160B: CHF dx
  * MCQ160C: CAD dx
  * MCQ160D: dx angina/angina pectoris
  * MCQ160E: MI dx
  * MCQ160F: Stroke dx
  * MCQ160G: dx emphysema
  * MCQ180B: Age of CHF dx
  * MCQ180C: Age of CAD dx
  * MCQ180D: Age of angina/angina pectoris dx
  * MCQ180E: Age of MI dx
  * MCQ180F: Age of stroke Dx
  * MCQ180G: Age of emphysema dx
  * MCQ300A: close relative who had MI
  * MCQ300B: close relative who had asthma
  * MCQ300C: close relative who had diabetes
* Occupation
  * None
* Physical Activity (Describes subsections of activities, likely not needed)
  * None
* Physical Activity - Individual Activities
  * PADACTIV: over the past 30 days, what vigorous/moderate activities did you do?
  * PADLEVEL: reported intensity level of activity
  * PADTIMES: how often did you do activities over the past 30 days?
  * PADDRAT: average duration of the activities (minutes)
* Physical Functioning
  * PFQ020: Do you have impairment or health problem that limits your ability to crawl/walk/...?
  * PFQ030: Is the impairment chronic or acute (>= 12 months)?
* Prescription Medications
  * None
* Respiratory Health
  * None
* Smoking - Cigarette Use
  * SMQ020: smoked at least 100 cigs in life
  * SMD030: age started smoking regularly
  * SMQ040: do you now smoke cigs still?
  * SMQ050Q: if not smoking, how long ago did you stop?
  * SMQ050U: unit of days/week/months/year
* Smoking - Household Smokers
  * None
* Smoking - Recent Tobacco Use
  * None
* Social Support
  * None
* Weight History
  * WHD010: current self-reported height (inches)
  * WHD020: current self-reported weight (lbs)
  * WHQ030: how do subject feel about their weight
  * WHQ040: like to weigh more/less/same
  * WHQ060: is weight change intentional?
* Weight History - Youth
  * None

```{r que_var_keep}

que_remove_list <- c("Bowel Health", "Diet Behavior", "Drug", "Early Childhood", "Health Insurance", "Hospital Utilization", 
                     "Housing Characteristic", "Immunization", "Occupation", "Prescription Medication", "Respiratory Health",
                     "Household Smokers", "Recent Tobacco Use", "Social Support", "Weight History - Youth")

que_keep_list <- c("SEQN", "ALQ120Q", "ALQ120U", "BPQ040A", "BPQ070", "BPQ080", "BPQ090", "CDQ", "DIQ", "HSD010", "FSD032", "FSD041", 
                   "FSD052", "FSD061", "FSD071", "FSD081", "FSD092", "FSD102", "MCQ010", "MCQ025", "MCQ035", "MCQ080", 
                   "MCQ160B", "MCQ160C", "MCQ160D", "MCQ160E", "MCQ160F", "MCQ160G", "MCQ180B", "MCQ180C", "MCQ180D", 
                   "MCQ180E", "MCQ180F", "MCQ180G", "MCQ300A", "MCQ300B", "MCQ300C", "PADACTIV", "PADLEVEL", "PADTIMES", 
                   "PADDRAT", "PFQ020", "PFQ030", "SMQ020", "SMD030", "SMQ040", "SMQ050Q", "SMQ050U", "WHD010", "WHD020", 
                   "WHQ030", "WHQ040", "WHQ060", "DID")

que_survey <- que_survey %>% 
  filter(!(str_detect(data_desc, paste(que_remove_list, collapse = "|"))),
         str_detect(var_name, paste(que_keep_list, collapse = "|")))

```

### Limited Data

```{r lim_survey}

lim_survey <- det_selected_df %>% 
  filter(survey_type == "limited_data") %>% 
  select(-survey_type, -filedata)

# used to check "unique" data descriptions to quickly filter out which categories might be of interest to explore
janitor::get_dupes(lim_survey, var_name)

lim_survey %>% 
  distinct(data_desc)

```

Variables of interest:

* Geocoded Data, NHANES 1999-2016, Census 2010
  
```{r limvar_keep}

lim_survey <- lim_survey %>% 
  filter(str_detect(data_desc, "Census 2010"))

```


#### Combining all the filtered database to isolate the variable names

```{r final_variables}

final_df <- bind_rows(demo_survey, diet_survey, exam_survey, lab_survey, que_survey, lim_survey)

final_df <- final_df %>% 
  distinct(var_name, var_desc)

```

